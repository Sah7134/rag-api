# AI/ML Applied â€“ RAG API (FastAPI + Gemini + FAISS)

Une API **de dÃ©monstration** qui combine :  
- **FastAPI** pour lâ€™exposition des endpoints,  
- **Google Gemini** pour la gÃ©nÃ©ration de texte,  
- **FAISS** pour lâ€™indexation et la recherche vectorielle (RAG),  
- **Docker** + **Cloud Run** pour le dÃ©ploiement cloud.  

Ce projet illustre une compÃ©tence clÃ© dâ€™**AI/ML Engineer appliquÃ©** :  
ğŸ‘‰ construire et dÃ©ployer une API de bout en bout qui exploite lâ€™IA de maniÃ¨re concrÃ¨te.

---

## ğŸš€ FonctionnalitÃ©s

- Endpoint `/chat` : conversation simple avec le modÃ¨le choisi.  
- Endpoint `/rag/add_text` : ajout de texte dans lâ€™index vectoriel FAISS.  
- Endpoint `/rag/answer` : rÃ©ponse Ã  une question en sâ€™appuyant sur les documents indexÃ©s (RAG).  
- Endpoint `/metrics` : statistiques (uptime, total de requÃªtes, latence p50/p90/p99).  
- Endpoint `/health` : vÃ©rification de lâ€™Ã©tat du service.  
- Documentation interactive via **Swagger UI** â†’ `/docs`.

---

## âš¡ Installation locale (sans Docker)

### 1. Cloner le projet
```bash
git clone https://github.com/Sah7134/rag-api.git
cd rag-api
```

### 2. CrÃ©er un environnement virtuel
```bash
python -m venv .venv
# Linux/macOS
source .venv/bin/activate
# Windows PowerShell
.\.venv\Scripts\Activate.ps1
```

### 3. Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```

### 4. Configurer lâ€™environnement
Copier `.env.example` â†’ `.env` et y ajouter votre clÃ© Gemini :

```
GOOGLE_GENAI_API_KEY=ta_cle
PROVIDER=gemini
MODEL=gemini-1.5-flash
EMBED_MODEL=text-embedding-004
```

### 5. Lancer lâ€™API
```bash
uvicorn main:app --reload
```

### 6. Tester
- Swagger UI : [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)  
- Health check : [http://127.0.0.1:8000/health](http://127.0.0.1:8000/health)

---

## ğŸ³ Installation avec Docker

### 1. Construire lâ€™image
```bash
docker build -t rag-api:latest .
```

### 2. Lancer un conteneur
```bash
docker run -p 8000:8000 rag-api:latest
```

### 3. AccÃ©der
- Swagger UI : [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

---

## â˜ï¸ DÃ©ploiement Cloud Run

1. Construire et pousser lâ€™image vers Artifact Registry :  
```bash
docker build -t $IMAGE .
docker push $IMAGE
```

2. DÃ©ployer sur Cloud Run :  
```bash
gcloud run deploy rag-api   --image $IMAGE   --region $REGION   --platform managed   --allow-unauthenticated   --port 8080   --set-env-vars "PROVIDER=gemini,MODEL=gemini-1.5-flash,EMBED_MODEL=text-embedding-004"   --set-secrets "GOOGLE_GENAI_API_KEY=google-genai-key:latest"
```

3. RÃ©cupÃ©rer lâ€™URL publique :  
```bash
gcloud run services describe rag-api --region $REGION --format "value(status.url)"
```

---

## âœ… Tests (pytest)

Deux tests simples (`test_smoke.py`) sont inclus :  
- VÃ©rification du `/health`.  
- VÃ©rification du `/chat_qs` avec un mock.

ExÃ©cuter :  
```bash
pytest -q
```

---

## ğŸ“Š Exemple de requÃªte RAG

### Ajouter un texte
```bash
curl -X POST "http://127.0.0.1:8000/rag/add_text" -H "Content-Type: application/json" -d "Le Soleil est une Ã©toile."
```

### Poser une question
```bash
curl -X POST "http://127.0.0.1:8000/rag/answer" -H "Content-Type: application/json" -d "Explique le Soleil en 3 phrases."
```

RÃ©ponse attendue :  
```json
{
  "answer": "Le Soleil est une Ã©toile au centre du systÃ¨me solaire...",
  "sources": [...],
  "citations": [1,2,3]
}
```

---

## ğŸ“Œ Points clÃ©s du projet

- **Serverless** : dÃ©ploiement via Cloud Run (scaling auto, aucun serveur Ã  maintenir).  
- **SÃ©curitÃ©** : clÃ© API stockÃ©e dans Secret Manager.  
- **Reproductible** : `.env.example`, `requirements.txt`, Dockerfile, README clair.  
- **Portfolio** : projet dÃ©monstratif dâ€™AI/ML Engineer appliquÃ©.

---

## ğŸ‘¤ Auteur
**Amin HassaÃ¯ni**  
ğŸ“§ contact@aminhassaini.be  
ğŸ’» [GitHub](https://github.com/Sah7134)  
